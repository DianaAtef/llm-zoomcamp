{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f6f8ae2-55f4-4e51-b84c-bf8203727fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Loads environment variables from the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74dad887-5f94-4956-8a7b-3cf1e8b81514",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_key = os.environ.get(\"hf_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6c16d71-0966-46c7-aab2-eff09510ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "headers = {\"Authorization\": \"Bearer \" + hf_key}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"What is a Large Language Model? \",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5799d3eb-495f-44e3-8273-87eb53fdca0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a Large Language Model? \\n\\nA large language model is a type of artificial intelligence (AI) model that is designed to understand and generate human-like text. It is trained on vast amounts of data, such as books, websites, and other text, to learn patterns and relationships in language. Large language models can be used for various tasks, such as answering questions, writing essays, summarizing text, and even generating creative content like poetry or stories. These models can process and understand complex contexts and generate responses that'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f521cde5-454a-464d-be8d-5a984235405e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
